# Pipeline to run the HPU tests in DL1 Instance

trigger:
  tags:
    include: ["*"]
  branches:
    include:
      - "main"
      - "release/*"
      - "refs/tags/*"

pr:
  branches:
    include:
      - "main"
      - "release/*"

schedules:
- cron: '0 0 * * *'
  displayName: Daily midnight check
  branches:
    include: ["main"]

jobs:
  - job: testing
    # how long to run the job before automatically cancelling
    timeoutInMinutes: "35"
    # how much time to give 'run always even if cancelled tasks' before stopping them
    cancelTimeoutInMinutes: "2"
    strategy:
      matrix:
        'w. pytorch-lightning | pypi':
          image: "1.17.0/ubuntu22.04/habanalabs/pytorch-installer-2.3.1:latest"
          dependency: "pytorch-lightning"
          pkg_source: "pypi"
        'w. pytorch-lightning | source':
          image: "1.17.0/ubuntu22.04/habanalabs/pytorch-installer-2.3.1:latest"
          dependency: "pytorch-lightning"
          pkg_source: "source"
        'w. lightning | pypi':
          image: "1.17.0/ubuntu22.04/habanalabs/pytorch-installer-2.3.1:latest"
          dependency: "lightning"
          pkg_source: "pypi"
        'w. lightning | source':
          image: "1.17.0/ubuntu22.04/habanalabs/pytorch-installer-2.3.1:latest"
          dependency: "lightning"
          pkg_source: "source"
    pool: "intel-hpus"
    container:
      image: "vault.habana.ai/gaudi-docker/$(image)"
      options: "--runtime=habana \
                -e HABANA_VISIBLE_DEVICES=all \
                -e OMPI_MCA_btl_vader_single_copy_mechanism=none \
                --cap-add=sys_nice \
                --ipc=host \
                --shm-size=4g \
                -v /usr/bin/docker:/tmp/docker:ro"
    variables:
      DEVICES: $( python -c 'print("$(Agent.Name)".split("_")[-1])' )
      MODULE_ID: $( python -c 'print("$(Agent.Name)".split("_")[-1])' )
      DEEPSPEED_VERSION: "1.17.0"

    workspace:
      clean: all

    steps:
    - bash: |
        # echo "##vso[task.setvariable variable=HABANA_VISIBLE_DEVICES]$(DEVICES)"
        echo "##vso[task.setvariable variable=HABANA_VISIBLE_MODULES]$(MODULE_ID)"
      displayName: "set env. vars"

    - bash: |
        hl-smi
        lsmod | grep habanalabs
        echo "HABANA_VISIBLE_DEVICES=$HABANA_VISIBLE_DEVICES"
        echo "HABANA_VISIBLE_MODULES=$HABANA_VISIBLE_MODULES"
        hl-smi -Q index,module_id -f csv
        python --version
        pip --version
      displayName: 'Instance HW info'

    - bash: |
        set -ex
        pip install ".[$(dependency)]" -r requirements/_test.txt
        pip install git+https://github.com/HabanaAI/DeepSpeed.git@$(DEEPSPEED_VERSION)
      displayName: 'Install package & dependencies'

    - bash: pip install https://github.com/Lightning-AI/lightning/archive/refs/heads/release/stable.zip
      condition: eq(variables['pkg_source'], 'source')
      displayName: 'OverInstall lightning from source'

    - bash: pip uninstall -y pytorch-lightning
      condition: eq(variables['dependency'], 'lightning')
      displayName: 'drop PL package'

    - bash: pip uninstall -y lightning
      condition: eq(variables['dependency'], 'pytorch-lightning')
      displayName: 'drop Lightning package'

    # todo: add sanity check that needed cards are visible and accessible

    - bash: |
        set -ex
        pip list
        # todo: consider test all files not listed as you may easily forget to add new
        python -m pytest -sv \
          tests/test_fabric/test_accelerator.py \
          tests/test_fabric/test_strategy.py \
          tests/test_fabric/test_precision.py \
          --hpus 1 --junitxml=hpu_test-fabric-results.xml
        python -m pytest -sv \
          tests/test_pytorch/test_accelerator.py \
          tests/test_pytorch/test_hpu_graphs.py \
          tests/test_pytorch/test_dynamic_shapes.py \
          tests/test_pytorch/test_datamodule.py \
          tests/test_pytorch/test_profiler.py \
          tests/test_pytorch/test_precision.py \
          tests/test_pytorch/strategies/test_hpu_parallel.py \
          tests/test_pytorch/strategies/test_hpu_ddp.py \
          --hpus 1 -m "not standalone_only" \
          --junitxml=hpu_test-torch-results.xml
      displayName: 'HPU General tests'

    - bash: |
        python -m pytest -sv tests/test_pytorch/test_compile.py \
          --hpus 1 --junitxml=hpu_compile_test-results.xml
      env:
        PT_HPU_LAZY_MODE: 0
      displayName: 'HPU torch compile tests'

    # - bash: |
    #     python -m pytest -sv tests/test_fabric/test_fsdp.py \
    #       --hpus 1 --junitxml=hpu_test_fsdp-fabric-results.xml
    #     python -m pytest -sv tests/test_pytorch/strategies/test_fsdp.py \
    #       --hpus 1 --junitxml=hpu_test_fsdp-results.xml
    #   env:
    #     PT_HPU_LAZY_MODE: 0
    #   displayName: 'HPU FSDP tests'

    - bash: |
        python -m pytest -sv tests/test_pytorch/strategies/test_deepspeed.py \
        -m "not standalone_only" --junitxml=hpu_deepspeed_test-results.xml
      displayName: 'HPU Deepspeed tests'

    - bash: |
        python -m pytest -sv tests/test_pytorch/test_precision.py \
          -k test_autocast_operators_override --runxfail \
          --junitxml=hpu_precision_test_override-results.xml
      env:
        LOWER_LIST: tests/test_pytorch/ops_fp32.txt
        FP32_LIST: tests/test_pytorch/ops_bf16.txt
      displayName: 'HPU precision test'

    - bash: |
        bash tests/run_standalone_tests.sh --hpus 1 -m standalone_only -f \
          tests/test_pytorch/strategies/test_hpu_parallel.py \
          tests/test_pytorch/test_precision.py \
          tests/test_pytorch/test_dynamic_shapes.py
      displayName: Standalone-only single card tests

    - bash: |
        bash tests/run_standalone_tests.sh --hpus 2 -f \
          tests/test_pytorch/test_accelerator.py \
          tests/test_pytorch/test_compile.py \
          tests/test_pytorch/test_profiler.py
      displayName: 'Multi card(2) HPU test'

    - bash: |
        # bash tests/run_standalone_tests.sh --hpus 2 -f \
        #   tests/test_pytorch/test_fsdp.py
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_custom_mixed_precision  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_strategy_sync_batchnorm  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_simple_model[SHARD_GRAD_OP]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_simple_model[FULL_SHARD]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_simple_model[NO_SHARD]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_simple_model_activation_cp[SHARD_GRAD_OP]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_simple_model_activation_cp[FULL_SHARD]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_simple_model_activation_cp[NO_SHARD]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_simple_model_activation_cp_mixed_precision[SHARD_GRAD_OP]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_simple_model_activation_cp_mixed_precision[FULL_SHARD]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_simple_model_activation_cp_mixed_precision[NO_SHARD]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_strategy_simple_model_compile  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_modules_without_parameters  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_strategy_checkpoint[sharded]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_strategy_checkpoint[full]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_strategy_full_state_dict[1024]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_strategy_cpu_offload  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_configure_model[32-true-expected_dtype0]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_sharding_strategy  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_activation_checkpointing  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_precision_config[bf16-mixed-expected0]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_precision_config[32-true-expected1]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_strategy_save_optimizer_states[1024]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_strategy_load_optimizer_states[2]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_strategy_load_optimizer_states[1024]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_fsdp_strategy_load_optimizer_states[100000000]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_dummy_fsdp_string_init  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_hpu_parallel_precision_accuracy  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_hpu_fsdp_precision_accuracy  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_hpu_fsdp_reduce[sum]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_hpu_fsdp_reduce[max]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_hpu_fsdp_reduce[min]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
        python -m pytest -vs tests/test_pytorch/strategies/test_fsdp.py::test_hpu_fsdp_reduce[mean]  --hpus 2 --junitxml=hpu_test-fsdp-results.xml
      env:
        PT_HPU_LAZY_MODE: 0
      displayName: 'FSDP PT Multi card(2) HPU test'

    # - bash: |
    #     bash tests/run_standalone_tests.sh --hpus 2 -f \
    #       tests/test_fabric/test_fsdp.py
    #   env:
    #     PT_HPU_LAZY_MODE: 0
    # condition: or(eq(variables['HABANA_VISIBLE_MODULES'], '4,5'), eq(variables['HABANA_VISIBLE_MODULES'], '6,7'))
    # displayName: 'FSDP Fabric Multi card(2) HPU test'

    - bash: pip install ".[examples]"
      condition: or(eq(variables['HABANA_VISIBLE_MODULES'], '4,5'), eq(variables['HABANA_VISIBLE_MODULES'], '6,7'))
      displayName: 'Install extra for examples'

    - bash: |
        export PYTHONPATH="${PYTHONPATH}:$(pwd)"
        python pytorch/mnist_trainer.py
        python pytorch/hpu_graphs.py -v train --mode capture_and_replay make_graphed_callables modulecacher
        python pytorch/hpu_graphs.py -v inference --mode capture_and_replay wrap_in_hpu_graph
        python pytorch/hpu_graphs.py -v dynamicity --mode dynamic_control_flow dynamic_ops
        PT_HPU_LAZY_MODE=0 python pytorch/language_model.py -s SHARD_GRAD_OP -d 2
      workingDirectory: examples/
      condition: or(eq(variables['HABANA_VISIBLE_MODULES'], '4,5'), eq(variables['HABANA_VISIBLE_MODULES'], '6,7'))
      displayName: 'Testing HPU examples'

    - task: PublishTestResults@2
      inputs:
        testResultsFiles: '*-results.xml'
        testRunTitle: '$(Build.DefinitionName) - Python $(python.version)'
      condition: succeededOrFailed()
      displayName: 'Publish test results'
